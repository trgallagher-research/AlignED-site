<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Scoring and Reporting - AlignED Methodology</title>
  <meta name="description" content="How each AlignED benchmark is scored, what model pools are used, and why results are reported separately.">
  <link rel="stylesheet" href="../css/style.css">
</head>
<body>
  <header>
    <div class="container">
      <a href="../index.html" class="logo">AlignED</a>
      <button class="nav-toggle" aria-label="Toggle navigation">
        <span></span>
        <span></span>
        <span></span>
      </button>
      <nav>
        <a href="../index.html">Home</a>
        <a href="../about.html">About</a>
        <a href="../methodology/" class="active">Methodology</a>
        <a href="../results.html">Results</a>
        <a href="../benchmark-items.html">Benchmark Items</a>
        <a href="../data-access.html">Data & Contact</a>
      </nav>
    </div>
  </header>

  <main>
    <div class="page-header">
      <div class="container">
        <p class="text-muted"><a href="index.html">&larr; Methodology</a></p>
        <h1>Scoring and Reporting</h1>
        <p class="subtitle">How each benchmark is scored and why results are reported separately</p>
      </div>
    </div>

    <section class="content-section">
      <div class="container">
        <div class="prose">
          <h2>Scoring methods by benchmark</h2>
          <p>Each benchmark uses a different scoring approach, reflecting what it tests:</p>

          <table>
            <thead>
              <tr>
                <th>Benchmark</th>
                <th>Scoring method</th>
                <th>Scale</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td><strong>Neuromyth Identification</strong></td>
                <td>Binary correct/incorrect against a validated answer key (Dekker et al., 2012)</td>
                <td>0&ndash;100%</td>
              </tr>
              <tr>
                <td><strong>Diagnostic Reasoning</strong></td>
                <td>0&ndash;3 rubric per scenario, scored by an LLM judge (Claude 4.5 Sonnet)</td>
                <td>0&ndash;36 (raw) or 0&ndash;100%</td>
              </tr>
              <tr>
                <td><strong>General Pedagogical Knowledge (CDPK)</strong></td>
                <td>Multiple-choice items from standardised teacher certification exams</td>
                <td>0&ndash;100%</td>
              </tr>
              <tr>
                <td><strong>Inclusive Education (SEND)</strong></td>
                <td>Multiple-choice items from standardised teacher certification exams</td>
                <td>0&ndash;100%</td>
              </tr>
              <tr>
                <td><strong>ACARA Comparative Judgement</strong></td>
                <td>Pairwise comparison accuracy plus test-retest reliability across presentation orders</td>
                <td>0&ndash;100% (each metric)</td>
              </tr>
              <tr>
                <td><strong>ACARA Standards-Based Grading</strong></td>
                <td>Three-category classification (Above Satisfactory / Satisfactory / Below Satisfactory)</td>
                <td>0&ndash;100% accuracy per category</td>
              </tr>
            </tbody>
          </table>

          <p>Normalising these to a common scale would obscure important differences in what each score means. A 90% on neuromyth identification (binary classification of 32 items) is not comparable to a 90% on diagnostic reasoning (rubric-scored open responses judged by an LLM).</p>

          <h2>Model pools</h2>
          <p>Not all models appear in every benchmark. The model count varies because benchmarks were added at different times and some models cannot produce valid responses for certain task formats:</p>
          <ul>
            <li>Neuromyth Identification: 31 models</li>
            <li>Diagnostic Reasoning: 30 models</li>
            <li>General Pedagogical Knowledge (CDPK): 23 models</li>
            <li>Inclusive Education (SEND): 23 models</li>
            <li>ACARA Comparative Judgement: 12 models</li>
            <li>ACARA Standards-Based Grading (pilot): 7 models</li>
          </ul>

          <h2>Why results are reported separately</h2>
          <p>Performance on one benchmark does not predict performance on another. A model that scores well on pedagogical knowledge does not necessarily score well on neuromyth identification or student work judgement. For example:</p>
          <ul>
            <li>Gemini 2.5 Pro leads on pedagogical knowledge (88.5%) but scores 75.9% on neuromyth identification.</li>
            <li>ACARA comparative judgement rankings do not predict performance on any knowledge benchmark.</li>
            <li>The standards-based grading pilot produced near-chance accuracy from models that score above 80% on other tasks.</li>
          </ul>

          <p>Each evaluation is reported on its own terms. This lets users compare models on whatever capability matters most for their use case.</p>

          <p>See the <a href="../results.html">Results page</a> for all evaluations, or visit individual methodology pages for details on each benchmark.</p>

          <div class="btn-group mt-4">
            <a href="../results.html" class="btn btn-primary">View Results</a>
            <a href="index.html" class="btn btn-secondary">Back to Methodology</a>
          </div>
        </div>
      </div>
    </section>
  </main>

  <footer>
    <div class="container">
      <div class="footer-content">
        <div class="footer-brand">
          <a href="../index.html" class="logo">AlignED</a>
          <p>Benchmarking AI performance on professional teaching tasks.</p>
        </div>
        <div class="footer-links">
          <h4>Navigation</h4>
          <ul>
            <li><a href="../about.html">About</a></li>
            <li><a href="../methodology/">Methodology</a></li>
            <li><a href="../results.html">Results</a></li>
            <li><a href="../benchmark-items.html">Benchmark Items</a></li>
            <li><a href="../data-access.html">Data & Contact</a></li>
          </ul>
        </div>
        <div class="footer-links">
          <h4>Resources</h4>
          <ul>
            <li><a href="https://github.com/trgallagher-research/AlignED-site" target="_blank">GitHub</a></li>
          </ul>
        </div>
      </div>
      <p class="copyright">&copy; 2026 AlignED. All rights reserved.</p>
      <p class="copyright">Last updated: February 2026</p>
    </div>
  </footer>

  <script src="../js/main.js"></script>
</body>
</html>
