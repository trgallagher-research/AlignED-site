<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Full Results - AlignED</title>
  <meta name="description" content="Complete evaluation results for 21 AI models tested on AlignED v2 benchmarks, including two-tier composite scoring and ACARA student work judgement.">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
  <!-- Date adapter for timeline chart -->
  <script src="https://cdn.jsdelivr.net/npm/chartjs-adapter-date-fns"></script>
  <style>
    :root {
      --primary: #3B6B9A;
      --secondary: #7096B8;
      --accent: #4A7DB3;
      --background: #FAFAF8;
      --surface: #FFFFFF;
      --text: #2D3748;
      --text-muted: #718096;
      --border: #E2E6EA;
      --dark-header: #1A2B3C;
      --anthropic: #D97706;
      --openai: #10B981;
      --google: #3B82F6;
    }

    * { margin: 0; padding: 0; box-sizing: border-box; }

    body {
      font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
      background: var(--background);
      color: var(--text);
      line-height: 1.6;
    }

    a { color: var(--accent); text-decoration: none; }
    a:hover { text-decoration: underline; }

    .container { max-width: 1400px; margin: 0 auto; padding: 0 2rem; }

    /* Top Bar */
    .top-bar {
      background: var(--dark-header);
      color: white;
      padding: 0.5rem 0;
      font-size: 0.85rem;
    }
    .top-bar .container { display: flex; justify-content: flex-end; align-items: center; gap: 1rem; }
    .top-bar a { color: rgba(255,255,255,0.8); display: flex; align-items: center; gap: 0.5rem; }
    .top-bar a:hover { color: white; text-decoration: none; }
    .top-bar svg { width: 18px; height: 18px; }

    /* Navigation */
    .navbar {
      background: var(--surface);
      border-bottom: 1px solid var(--border);
      padding: 1rem 0;
      position: sticky;
      top: 0;
      z-index: 100;
    }
    .navbar .container { display: flex; justify-content: space-between; align-items: center; }
    .logo { font-size: 1.5rem; font-weight: 700; color: var(--primary); }
    .nav-links { display: flex; align-items: center; gap: 2rem; }
    .nav-links a { color: var(--text); font-weight: 500; font-size: 0.95rem; }
    .nav-links a:hover { color: var(--primary); text-decoration: none; }
    .nav-links a.active { color: var(--primary); }

    /* Page Header */
    .page-header {
      padding: 3rem 0 2rem;
      border-bottom: 1px solid var(--border);
    }
    .page-header h1 { font-size: 2rem; font-weight: 700; margin-bottom: 0.5rem; }
    .page-header p { color: var(--text-muted); font-size: 1.1rem; }

    /* Legend */
    .legend {
      display: flex;
      flex-wrap: wrap;
      gap: 2rem;
      padding: 1.5rem 0;
      font-size: 0.85rem;
      border-bottom: 1px solid var(--border);
    }

    .legend-item {
      display: flex;
      align-items: center;
      gap: 0.5rem;
      color: var(--text);
    }

    .legend-item svg {
      width: 22px;
      height: 22px;
    }

    /* Chart Sections */
    .chart-section {
      padding: 2rem 0;
      border-bottom: 1px solid var(--border);
    }

    .chart-header {
      margin-bottom: 1rem;
    }

    .chart-title {
      font-size: 1.25rem;
      font-weight: 600;
      color: var(--text);
      margin-bottom: 0.25rem;
    }

    .chart-subtitle {
      font-size: 0.9rem;
      color: var(--text-muted);
    }

    .chart-container {
      position: relative;
      width: 100%;
      height: 320px;
      background: var(--surface);
      border-radius: 8px;
      padding: 1rem;
      border: 1px solid var(--border);
    }

    /* Note callout */
    .note {
      background: #EBF4FF;
      border: 1px solid #BEE3F8;
      border-radius: 6px;
      padding: 1rem 1.5rem;
      margin: 1.5rem 0;
    }
    .note strong { color: var(--primary); }

    /* Footer */
    footer {
      background: var(--dark-header);
      color: white;
      padding: 2rem 0;
      margin-top: 2rem;
    }
    .footer-bottom {
      font-size: 0.85rem;
      color: rgba(255,255,255,0.5);
    }
    .footer-bottom a { color: rgba(255,255,255,0.7); }

    @media (max-width: 768px) {
      .nav-links { display: none; }
      .chart-container { height: 280px; }
    }
  </style>
</head>
<body>
  <!-- Top Bar -->
  <div class="top-bar">
    <div class="container">
      <span style="color: rgba(255,255,255,0.6);">Follow for updates:</span>
      <a href="#" target="_blank">
        <svg viewBox="0 0 24 24" fill="currentColor"><path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"/></svg>
      </a>
      <a href="#" target="_blank">
        <svg viewBox="0 0 24 24" fill="currentColor"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg>
      </a>
    </div>
  </div>

  <!-- Navigation -->
  <nav class="navbar">
    <div class="container">
      <a href="index.html" class="logo">AlignED</a>
      <div class="nav-links">
        <a href="about.html">About</a>
        <a href="methodology/">Methodology</a>
        <a href="results.html" class="active">Results</a>
        <a href="benchmark-items.html">Benchmark Items</a>
        <a href="data-access.html">Data</a>
        <a href="contact.html">Contact</a>
      </div>
    </div>
  </nav>

  <!-- Page Header -->
  <div class="page-header">
    <div class="container">
      <h1>Full Evaluation Results</h1>
      <p>AlignED v2 tested 21 models across four areas of educational knowledge. Results are shown in two tiers: a full composite (8 models with all four benchmarks) and a knowledge composite (all 21 models).</p>
    </div>
  </div>

  <!-- Legend -->
  <div class="container">
    <div class="legend">
      <div class="legend-item">
        <svg viewBox="0 0 24 24" fill="#10A37F"><path d="M22.2819 9.8211a5.9847 5.9847 0 0 0-.5157-4.9108 6.0462 6.0462 0 0 0-6.5098-2.9A6.0651 6.0651 0 0 0 4.9807 4.1818a5.9847 5.9847 0 0 0-3.9977 2.9 6.0462 6.0462 0 0 0 .7427 7.0966 5.98 5.98 0 0 0 .511 4.9107 6.051 6.051 0 0 0 6.5146 2.9001A5.9847 5.9847 0 0 0 13.2599 24a6.0557 6.0557 0 0 0 5.7718-4.2058 5.9894 5.9894 0 0 0 3.9977-2.9001 6.0557 6.0557 0 0 0-.7475-7.0729zm-9.022 12.6081a4.4755 4.4755 0 0 1-2.8764-1.0408l.1419-.0804 4.7783-2.7582a.7948.7948 0 0 0 .3927-.6813v-6.7369l2.02 1.1686a.071.071 0 0 1 .038.052v5.5826a4.504 4.504 0 0 1-4.4945 4.4944zm-9.6607-4.1254a4.4708 4.4708 0 0 1-.5346-3.0137l.142.0852 4.783 2.7582a.7712.7712 0 0 0 .7806 0l5.8428-3.3685v2.3324a.0804.0804 0 0 1-.0332.0615L9.74 19.9502a4.4992 4.4992 0 0 1-6.1408-1.6464zM2.3408 7.8956a4.485 4.485 0 0 1 2.3655-1.9728V11.6a.7664.7664 0 0 0 .3879.6765l5.8144 3.3543-2.0201 1.1685a.0757.0757 0 0 1-.071 0l-4.8303-2.7865A4.504 4.504 0 0 1 2.3408 7.872zm16.5963 3.8558L13.1038 8.364l2.0201-1.1685a.0757.0757 0 0 1 .071 0l4.8303 2.7913a4.4944 4.4944 0 0 1-.6765 8.1042v-5.6772a.79.79 0 0 0-.407-.667zm2.0107-3.0231l-.142-.0852-4.7735-2.7818a.7759.7759 0 0 0-.7854 0L9.409 9.2297V6.8974a.0662.0662 0 0 1 .0284-.0615l4.8303-2.7866a4.4992 4.4992 0 0 1 6.6802 4.66zM8.3065 12.863l-2.02-1.1638a.0804.0804 0 0 1-.038-.0567V6.0742a4.4992 4.4992 0 0 1 7.3757-3.4537l-.142.0805L8.704 5.459a.7948.7948 0 0 0-.3927.6813zm1.0976-2.3654l2.602-1.4998 2.6069 1.4998v2.9994l-2.5974 1.4997-2.6067-1.4997Z"/></svg>
        OpenAI
      </div>
      <div class="legend-item">
        <svg viewBox="0 0 24 24" fill="#D97757"><path d="M17.304 3.541h-3.672l6.696 16.918h3.672l-6.696-16.918zm-10.608 0L0 20.459h3.744l1.32-3.468h6.24l1.344 3.468h3.744L9.696 3.541h-3zm.816 10.584l2.184-5.592 2.16 5.592h-4.344z"/></svg>
        Anthropic
      </div>
      <div class="legend-item">
        <svg viewBox="0 0 24 24" fill="#4285F4"><path d="M22.56 12.25c0-.78-.07-1.53-.2-2.25H12v4.26h5.92c-.26 1.37-1.04 2.53-2.21 3.31v2.77h3.57c2.08-1.92 3.28-4.74 3.28-8.09z"/><path d="M12 23c2.97 0 5.46-.98 7.28-2.66l-3.57-2.77c-.98.66-2.23 1.06-3.71 1.06-2.86 0-5.29-1.93-6.16-4.53H2.18v2.84C3.99 20.53 7.7 23 12 23z"/><path d="M5.84 14.09c-.22-.66-.35-1.36-.35-2.09s.13-1.43.35-2.09V7.07H2.18C1.43 8.55 1 10.22 1 12s.43 3.45 1.18 4.93l2.85-2.22.81-.62z"/><path d="M12 5.38c1.62 0 3.06.56 4.21 1.64l3.15-3.15C17.45 2.09 14.97 1 12 1 7.7 1 3.99 3.47 2.18 7.07l3.66 2.84c.87-2.6 3.3-4.53 6.16-4.53z"/></svg>
        Google
      </div>
      <div class="legend-item">
        <span style="display:inline-block;width:22px;height:22px;background:#0668E1;border-radius:4px;"></span>
        Meta
      </div>
      <div class="legend-item">
        <span style="display:inline-block;width:22px;height:22px;background:#536DFE;border-radius:4px;"></span>
        DeepSeek
      </div>
    </div>
  </div>

  <!-- Charts -->
  <div class="container">

    <!-- Two-Tier Composite Explanation -->
    <section class="chart-section">
      <div class="chart-header">
        <h2 class="chart-title">How do models rank overall?</h2>
        <p class="chart-subtitle">AlignED uses a two-tier composite. The <strong>full composite</strong> (8 models) weights all four benchmarks equally: educational neuroscience (25%), classroom reasoning (25%), pedagogical knowledge (25%), and student work judgement (25%). The <strong>knowledge composite</strong> (21 models) uses three benchmarks: educational neuroscience (25%), classroom reasoning (25%), and pedagogical knowledge (50%).</p>
      </div>

      <div class="note" style="margin-bottom: 1.5rem;">
        <p><strong>Why two tiers?</strong> Only 8 of the 21 models were evaluated on the ACARA student work judgement benchmark. Rather than exclude 13 models from the ranking, we report both composites. Notable: Claude 4.5 Opus (Thinking) &mdash; ranked #2 on the knowledge composite &mdash; has no ACARA data, so it does not appear in the full composite.</p>
      </div>

      <!-- Full Composite (8 models) -->
      <p style="font-weight: 600; margin-bottom: 0.5rem;">Full Composite (8 models &mdash; all four benchmarks, 25% each)</p>
      <div class="chart-container" style="height: 280px;">
        <canvas id="fullCompositeChart"></canvas>
      </div>

      <!-- Knowledge Composite (21 models) -->
      <p style="font-weight: 600; margin-top: 1.5rem; margin-bottom: 0.5rem;">Knowledge Composite (21 models &mdash; three knowledge benchmarks)</p>
      <div class="chart-container">
        <canvas id="eaiChart"></canvas>
      </div>

      <div style="margin-top: 1rem; font-size: 0.9rem; color: var(--text);">
        <strong>Key observations:</strong>
        <ul style="margin-top: 0.5rem; padding-left: 1.25rem; color: var(--text-muted);">
          <li>GPT-5 leads both composites (90.8% full, 91.7% knowledge).</li>
          <li>There is a 31-point gap between the highest and lowest scoring models on the knowledge composite.</li>
          <li>Both OpenAI and Anthropic models appear in the top 5 of each tier.</li>
          <li>Adding ACARA to the composite changes some rankings: Claude 4 Sonnet rises from #13 to #5 on the full composite.</li>
        </ul>
      </div>
    </section>

    <!-- Educational Neuroscience (Neuromyths) -->
    <section class="chart-section">
      <div class="chart-header">
        <h2 class="chart-title">Can AI separate educational neuroscience from myths?</h2>
        <p class="chart-subtitle">32 items &mdash; 15 widely-believed myths about the brain and learning, plus 17 verified neuroscience facts. Models must correctly identify which is which. The average teacher gets about 50% right.</p>
      </div>
      <div class="chart-container">
        <canvas id="neuromythsChart"></canvas>
      </div>
      <div style="margin-top: 1rem; font-size: 0.9rem; color: var(--text);">
        <strong>Key observations:</strong>
        <ul style="margin-top: 0.5rem; padding-left: 1.25rem; color: var(--text-muted);">
          <li>GPT-5 and Claude 4.5 Opus (Thinking) lead at 92.9%.</li>
          <li>Even the lowest-scoring model (GPT-4o Mini, 54.5%) beats the human teacher baseline of ~50%.</li>
          <li>Several mid-tier models score above 85%, suggesting factual neuroscience knowledge is relatively strong across providers.</li>
        </ul>
      </div>
    </section>

    <!-- Classroom Reasoning (Scenarios) -->
    <section class="chart-section">
      <div class="chart-header">
        <h2 class="chart-title">Can AI diagnose why teaching strategies fail?</h2>
        <p class="chart-subtitle">12 realistic situations where an evidence-based teaching strategy isn't working. The model must explain why &mdash; not just recite the strategy. Each response is scored 0&ndash;3 by an expert judge.</p>
      </div>
      <div class="chart-container">
        <canvas id="scenariosChart"></canvas>
      </div>
      <div style="margin-top: 1rem; font-size: 0.9rem; color: var(--text);">
        <strong>Key observations:</strong>
        <ul style="margin-top: 0.5rem; padding-left: 1.25rem; color: var(--text-muted);">
          <li>Two models achieve perfect scores: GPT-5 and o3.</li>
          <li>Reasoning-focused models (o3, thinking variants) do especially well on this diagnostic task.</li>
          <li>This benchmark has the biggest spread of any &mdash; from 100% down to 55.6% &mdash; making it the most discriminating test.</li>
        </ul>
      </div>
    </section>

    <!-- Pedagogical Knowledge parent heading -->
    <div style="padding: 2rem 0 0;">
      <h2 style="font-size: 1.4rem; font-weight: 700; color: var(--text); margin-bottom: 0.25rem;">Does AI know what certified teachers know?</h2>
      <p style="font-size: 0.95rem; color: var(--text-muted); max-width: 800px;">1,143 items from real teacher certification assessments, split into general pedagogical knowledge (920 items) and inclusive education (223 items), shown separately below.</p>
    </div>

    <!-- CDPK (General Pedagogical Knowledge) -->
    <section class="chart-section">
      <div class="chart-header">
        <h2 class="chart-title">General Pedagogical Knowledge</h2>
        <p class="chart-subtitle">920 items covering cross-domain pedagogical knowledge from teacher certification exams</p>
      </div>
      <div class="chart-container">
        <canvas id="cdpkChart"></canvas>
      </div>
      <div style="margin-top: 1rem; font-size: 0.9rem; color: var(--text);">
        <strong>Key observations:</strong>
        <ul style="margin-top: 0.5rem; padding-left: 1.25rem; color: var(--text-muted);">
          <li>Gemini 2.5 Pro leads at 89.3% despite ranking #14 overall &mdash; the strongest pedagogical knowledge of any model.</li>
          <li>Anthropic models cluster in the 78&ndash;89% range, showing consistent but varied performance.</li>
          <li>The gap between top and bottom is smaller here than on other benchmarks, suggesting general pedagogical knowledge is more evenly distributed.</li>
        </ul>
      </div>
    </section>

    <!-- SEND (Inclusive Education) -->
    <section class="chart-section">
      <div class="chart-header">
        <h2 class="chart-title">Inclusive Education</h2>
        <p class="chart-subtitle">223 items on special education needs and disability (SEND) from teacher certification exams</p>
      </div>
      <div class="chart-container">
        <canvas id="sendChart"></canvas>
      </div>
      <div style="margin-top: 1rem; font-size: 0.9rem; color: var(--text);">
        <strong>Key observations:</strong>
        <ul style="margin-top: 0.5rem; padding-left: 1.25rem; color: var(--text-muted);">
          <li>Claude 4.5 Opus leads at 85.7%, closely followed by Gemini 2.5 Pro at 85.2%.</li>
          <li>Models generally score lower on inclusive education than general pedagogy &mdash; a potential gap in training data.</li>
          <li>The smallest models (Claude 3 Haiku, GPT-4o Mini) fall below 70%, a sharper drop-off than on general pedagogical knowledge.</li>
        </ul>
      </div>
    </section>

    <!-- Student Work Judgement (ACARA) -->
    <div style="padding: 2.5rem 0 0.5rem; border-top: 3px solid var(--primary); margin-top: 1rem;">
      <h2 style="font-size: 1.4rem; font-weight: 700; color: var(--text); margin-bottom: 0.25rem;">Student Work Judgement</h2>
      <p style="font-size: 0.95rem; color: var(--text-muted); max-width: 800px;">ACARA comparative judgement: can AI accurately compare student work against curriculum standards? This benchmark is now part of the full composite for the 8 models with data. 4 additional ACARA-only models (Llama 3.3, Gemini 3 Flash, Gemini 2.0 Flash, DeepSeek V3.2) appear here but not in either composite.</p>
    </div>

    <section class="chart-section">
      <div class="chart-header">
        <h2 class="chart-title">Accuracy and Consistency</h2>
        <p class="chart-subtitle">79 pairs of Australian student work samples. Tested in both orders to check consistency. 12 models evaluated. <a href="methodology/acara.html">View methodology &rarr;</a></p>
      </div>
      <div class="chart-container" style="height: 380px;">
        <canvas id="acaraChart"></canvas>
      </div>
      <div style="margin-top: 1rem; font-size: 0.9rem; color: var(--text);">
        <strong>Key observations:</strong>
        <ul style="margin-top: 0.5rem; padding-left: 1.25rem; color: var(--text-muted);">
          <li>No clear correlation with the knowledge composite &mdash; Claude 4.5 Haiku (#15 on knowledge) is #3 on ACARA accuracy.</li>
          <li>GPT-5 has the highest consistency (94.1%) but not the highest accuracy, suggesting strong position-invariance.</li>
          <li>Gemini 3 Flash shows a big accuracy-consistency gap (81% vs 69%), suggesting position bias in its judgements.</li>
        </ul>
      </div>
    </section>

    <!-- Cost and Token Usage -->
    <div style="padding: 2.5rem 0 0.5rem; border-top: 3px solid var(--primary); margin-top: 1rem;">
      <h2 style="font-size: 1.4rem; font-weight: 700; color: var(--text); margin-bottom: 0.25rem;">Cost and Efficiency</h2>
      <p style="font-size: 0.95rem; color: var(--text-muted); max-width: 800px;">How many tokens does each model use to complete the survey and scenarios? Thinking models generate internal reasoning tokens that increase cost substantially, even when the final answer is the same length.</p>
    </div>

    <section class="chart-section">
      <div class="chart-header">
        <h2 class="chart-title">Token Usage: Survey + Scenarios</h2>
        <p class="chart-subtitle">Total tokens (prompt + completion + reasoning) for 32 educational neuroscience items and 12 classroom scenarios. 18 models with available data.</p>
      </div>
      <div class="chart-container" style="height: 450px;">
        <canvas id="tokenChart"></canvas>
      </div>
      <div style="margin-top: 1rem; font-size: 0.9rem; color: var(--text);">
        <strong>Key observations:</strong>
        <ul style="margin-top: 0.5rem; padding-left: 1.25rem; color: var(--text-muted);">
          <li>Thinking models average ~20,000 tokens vs ~6,000 for standard models &mdash; roughly 3&times; more.</li>
          <li>Gemini 2.5 Pro uses the most tokens (38,069) due to extensive internal reasoning, despite moderate accuracy.</li>
          <li>Standard Claude and GPT-4o models cluster tightly around 5,300&ndash;6,700 tokens.</li>
          <li>Token counts here cover only survey + scenarios; the full evaluation (including 1,143 pedagogy items) costs significantly more.</li>
        </ul>
      </div>
    </section>

    <!-- Model Timeline -->
    <section class="chart-section">
      <div class="chart-header">
        <h2 class="chart-title">Model Release Timeline</h2>
        <p class="chart-subtitle">When each model was released and how it scored. Later models tend to score higher, but the relationship is not linear &mdash; architecture and training choices matter as much as release date.</p>
      </div>
      <div class="chart-container" style="height: 380px;">
        <canvas id="timelineChart"></canvas>
      </div>
      <div style="margin-top: 1rem; font-size: 0.9rem; color: var(--text);">
        <strong>Key observations:</strong>
        <ul style="margin-top: 0.5rem; padding-left: 1.25rem; color: var(--text-muted);">
          <li>Models from late 2025 generally outperform those from early 2024, but there is wide variation within each period.</li>
          <li>Claude 3 Haiku (March 2024) scores 60.3% while Claude 4.5 Opus (November 2025) scores 89.8% &mdash; a 29.5 point improvement in 20 months from the same provider.</li>
          <li>GPT-4 Turbo (November 2023) and GPT-4o (May 2024) score similarly (~73%), while GPT-5 (August 2025) jumps to 91.7%.</li>
        </ul>
      </div>
    </section>

    <!-- What do these results mean? -->
    <section class="chart-section" style="border-bottom: none;">
      <h2 style="font-size: 1.4rem; font-weight: 700; color: var(--text); margin-bottom: 1rem;">What do these results mean?</h2>
      <ul style="font-size: 0.95rem; color: var(--text); line-height: 1.8; padding-left: 1.25rem;">
        <li>The best models exceed 90%, well above what human teachers typically achieve on the same types of assessments.</li>
        <li>Reasoning-focused models (o3, thinking variants) excel at diagnostic scenarios but don't consistently lead on factual knowledge.</li>
        <li>Model size matters &mdash; smaller and cheaper models consistently score lowest across all benchmarks.</li>
        <li>Pedagogical knowledge varies independently of other skills &mdash; Gemini 2.5 Pro is #1 on pedagogical knowledge but #14 overall.</li>
        <li>Student work judgement is a different capability: ACARA rankings don't predict knowledge composite rankings.</li>
        <li>The full composite (with ACARA) changes some rankings meaningfully &mdash; Claude 4 Sonnet jumps from #13 to #5 when applied assessment is included.</li>
        <li>Thinking models use 3&times; more tokens but don't always score higher, raising questions about cost-effectiveness for educational applications.</li>
      </ul>
    </section>
  </div>

  <!-- Footer -->
  <footer>
    <div class="container">
      <div class="footer-bottom">
        &copy; 2026 AlignED. Data hosted on OSF. <a href="index.html">Back to Home</a>
      </div>
    </div>
  </footer>

  <script src="js/charts.js"></script>
</body>
</html>
